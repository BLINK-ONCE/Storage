# 5.2.2 Regularization

## 번역

무료 점심식사 정리는 우리가 특정 작업에서 잘 수행할 수 있도록 기계 학습 알고리듬을 설계해야 한다는 것을 암시한다. 우리는 일련의 선호도를 학습 알고리듬으로 구축함으로써 그렇게 한다. 이러한 선호도가 알고리듬이 해결하도록 요구하는 학습 문제와 일치하면 더 나은 성능을 발휘한다.

지금까지 우리가 구체적으로 논의한 학습 알고리듬을 수정하는 유일한 방법은 학습 알고리듬이 선택할 수 있는 솔루션의 가설 공간에서 함수를 추가하거나 제거하여 모델의 표현 능력을 증가시키거나 감소시키는 것이다. 회귀 문제에 대한 다항식의 정도를 증가 또는 감소시키는 구체적인 예를 제시했다. 우리가 지금까지 설명한 관점은 지나치게 단순하다.

알고리듬의 동작은 우리가 가설 공간에서 허용되는 함수 집합을 얼마나 크게 만드는가에 의해서뿐만 아니라, 그러한 함수의 특정한 정체성에 의해서도 강하게 영향을 받는다. 지금까지 연구한 학습 알고리듬인 선형 회귀에는 입력의 선형 함수 집합으로 구성된 가설 공간이 있다. 이러한 선형 함수는 입력과 출력 사이의 관계가 실제로 선형에 가까운 문제에 매우 유용할 수 있다. 그것들은 매우 비선형적인 방식으로 작용하는 문제에는 덜 유용하다. 예를 들어, 선형 회귀 분석을 사용하여 x에서 sin(x)을 예측하려고 하면 선형 회귀 분석이 잘 수행되지 않을 것이다. 따라서 우리는 알고리즘이 솔루션을 끌어낼 수 있는 기능의 종류를 선택하고 이러한 함수의 양을 제어함으로써 알고리듬의 성능을 제어할 수 있다.

우리는 또한 학습 알고리듬이 가설 공간에서 다른 솔루션에 대한 선호도를 제공할 수 있다. 이는 두 기능이 모두 적용 가능하지만 한 기능이 선호된다는 것을 의미한다. 선호되지 않는 솔루션은 선호되는 솔루션보다 교육 데이터에 훨씬 더 적합한 경우에만 선택됩니다.

예를 들어, 우리는 체중 감소를 포함하도록 선형 회귀에 대한 훈련 기준을 수정할 수 있다. 체중 감소와 함께 선형 회귀를 수행하기 위해, 우리는 훈련의 평균 제곱 오차와 가중치가 더 작은 제곱 L2 규범을 갖는 선호도를 나타내는 기준 J(w)로 구성된 합계를 최소화한다. 구체적으로,

J(w) = MSE(Train) + (lambda)w^(T) w

여기서 α는 더 작은 무게에 대한 우리의 선호의 강도를 조절하는 미리 선택된 값입니다. α = 0일 때, 우리는 선호하지 않으며, α가 클수록 가중치가 작아진다. J(w)를 최소화하면 훈련 데이터를 적합시키는 것과 작은 것 사이의 절충을 이루는 가중치를 선택할 수 있다. 따라서 기울기가 더 작거나 더 적은 기능에 무게를 두는 솔루션을 얻을 수 있습니다. 가중치 감소를 통해 모델의 과적합 또는 과소적합 경향을 제어할 수 있는 방법의 예로서, 서로 다른 α 값을 갖는 고차원 다항식 회귀 모델을 훈련할 수 있다. 결과는 그림 5.5를 참조하십시오.

그림 5.5: 우리는 그림 5.2의 예제 훈련 세트에 고차원 다항식 회귀 모델을 적합시킨다. 실제 함수는 2차 함수이지만 여기서는 정도가 9인 모형만 사용합니다. 우리는 이러한 고차원적 모델이 과적합되지 않도록 체중 감소량을 변화시킨다. (왼쪽)α가 매우 크면 모델이 경사가 전혀 없는 함수를 학습하도록 할 수 있다. 이것은 상수 함수만 나타낼 수 있기 때문에 적합하지 않습니다. (중앙)α의 중간값으로 학습 알고리즘은 일반 형상이 맞는 곡선을 복구한다.
모형이 훨씬 더 복잡한 모양을 가진 함수를 나타낼 수 있지만, 체중 감소는 더 작은 계수로 설명되는 간단한 함수를 사용하도록 유도했다. (오른쪽)체중 감소가 0에 가까워지면(즉, 최소 정규화로 결정되지 않은 문제를 해결하기 위해 무어-펜로즈 의사 역수를 사용함) 그림 5.2에서 보았던 것처럼 도-9 다항식이 크게 적합해진다.

보다 일반적으로, 우리는 비용 함수에 정규화기라는 페널티를 추가하여 함수 f(x; (alpha))를 학습하는 모델을 정규화할 수 있다. 중량 붕괴의 경우, 정규화기는 (ohm)(w) = w^(T)w이다. 7장에서, 우리는 다른 많은 정규화기가 가능하다는 것을 알게 될 것이다.

한 함수에 대한 선호도를 다른 함수에 비해 표현하는 것이 가설 공간에서 멤버를 포함하거나 제외하는 것보다 모형의 용량을 제어하는 더 일반적인 방법입니다. 우리는 가설 공간에서 함수를 제외하는 것을 그 함수에 대해 무한히 강한 선호도를 표현하는 것으로 생각할 수 있다.

우리의 체중 감소 예제에서, 우리는 최소화 기준의 추가 항을 통해 더 작은 가중치로 정의된 선형 함수에 대한 선호도를 명시적으로 표현했다. 암묵적으로나 명시적으로 다른 솔루션에 대한 선호를 표현하는 많은 다른 방법이 있다. 이러한 다양한 접근 방식을 함께 정규화라고 한다. 정규화는 일반화 오류를 줄이려고 의도된 학습 알고리듬에 대한 수정이지만 훈련 오류는 수정하지 않는다. 정규화는 기계 학습 분야의 중심 관심사 중 하나이며 최적화에 의해서만 그 중요성에 맞섰다.

무료 점심식사 정리는 최고의 기계 학습 알고리듬이 없으며, 특히 정규화의 최상의 형태가 없다는 것을 분명히 했다. 대신 우리는 우리가 해결하고자 하는 특정 과제에 잘 맞는 정규화의 형태를 선택해야 한다. 일반적으로 딥 러닝의 철학과 특히 이 책은 매우 광범위한 작업(사람들이 할 수 있는 모든 지적 작업 등)이 모두 매우 범용적인 형태의 정규화를 사용하여 효과적으로 해결될 수 있다는 것이다.

# 5.3 Hyperparameters and Validation Sets

## 번역

대부분의 머신 러닝 알고리듬은 학습 알고리듬의 동작을 제어하는 데 사용할 수 있는 몇 가지 설정을 가지고 있다. 이러한 설정을 하이퍼 파라미터라고 합니다. 하이퍼 파라미터의 값은 학습 알고리듬 자체에 의해 조정되지 않는다(그러나 우리는 한 학습 알고리듬이 다른 학습 알고리듬에 대한 최상의 하이퍼 파라미터를 학습하는 중첩 학습 절차를 설계할 수 있다).

그림 5.2에서 본 다항식 회귀 예제에는 용량 하이퍼 파라미터로 작동하는 다항식의 정도인 단일 하이퍼 파라미터가 있다. 체중 감소 강도를 조절하는 데 사용되는 α 값은 하이퍼 파라미터의 또 다른 예입니다.

때때로 설정은 최적화하기 어렵기 때문에 학습 알고리듬이 학습하지 않는 하이퍼 파라미터로 선택된다. 더 자주 설정은 훈련 세트에서 해당 하이퍼 매개 변수를 학습하는 것이 적절하지 않기 때문에 하이퍼 매개 변수여야 한다. 이는 모델 용량을 제어하는 모든 하이퍼 파라미터에 적용됩니다. 훈련 세트에 대해 학습한 경우, 그러한 초 매개 변수는 항상 가능한 최대 모델 용량을 선택하므로 과적합이 발생한다(그림 5.3 참조). 예를 들어, 우리는 낮은 정도 다항식과 양의 무게 붕괴 설정보다 높은 정도 다항식과 α = 0의 무게 붕괴 설정으로 항상 훈련 세트를 더 잘 적합시킬 수 있다.

이 문제를 해결하기 위해 훈련 알고리듬이 관찰하지 않는 예제의 검증 세트가 필요하다.

앞서 우리는 학습 과정이 완료된 후, 교육 세트와 동일한 분포에서 나온 예들로 구성된 보류된 테스트 세트를 학습자의 일반화 오류를 추정하는 데 어떻게 사용할 수 있는지에 대해 논의하였다. 테스트 예제는 초 매개 변수를 포함하여 모델에 대한 선택을 위해 어떤 방식으로도 사용되지 않는 것이 중요합니다. 이러한 이유로 테스트 세트의 예는 유효성 검사 세트에 사용할 수 없습니다. 따라서, 우리는 항상 교육 데이터에서 검증 세트를 구성한다. 특히, 우리는 훈련 데이터를 두 개의 분리된 부분 집합으로 분할했다. 이러한 하위 집합 중 하나가 매개 변수를 학습하는 데 사용됩니다. 다른 하위 집합은 우리의 유효성 검사 집합으로, 훈련 중 또는 훈련 후 일반화 오류를 추정하는 데 사용되며 이에 따라 하이퍼 파라미터가 업데이트될 수 있다. 매개 변수를 학습하는 데 사용되는 데이터의 하위 집합은 전체 훈련 프로세스에 사용되는 더 큰 데이터 풀과 혼동될 수 있지만 여전히 일반적으로 훈련 집합이라고 불린다. 하이퍼 파라미터 선택을 안내하는 데 사용되는 데이터의 하위 집합을 유효성 검사 집합이라고 합니다. 일반적으로 교육 데이터의 약 80%를 교육에 사용하고 20%를 검증에 사용합니다. 유효성 검사 세트는 하이퍼 파라미터를 "트레이닝"하는 데 사용되기 때문에, 유효성 검사 세트 오류는 일반적으로 훈련 오류보다 적은 양으로 일반화 오류를 과소평가한다. 모든 하이퍼 파라미터 최적화가 완료된 후 테스트 세트를 사용하여 일반화 오류를 추정할 수 있습니다.

실제로, 동일한 테스트 세트가 여러 해에 걸쳐 서로 다른 알고리듬의 성능을 평가하기 위해 반복적으로 사용되어 왔고, 특히 우리가 그 테스트 세트에서 보고된 최첨단 성능을 능가하는 과학계의 모든 시도를 고려할 경우, 우리는 테스트 세트로도 낙관적인 평가를 하게 된다. 따라서 벤치마크는 오래되어 훈련된 시스템의 실제 현장 성능을 반영하지 못할 수 있다. 다행히, 커뮤니티는 새로운(일반적으로 더 야심차고 더 큰) 벤치마크 데이터 세트로 이동하는 경향이 있다.

### Cross-Validation

데이터 세트를 고정 훈련 세트와 고정 테스트 세트로 나누는 것은 테스트 세트가 작아지는 결과를 가져올 경우 문제가 될 수 있다. 작은 테스트 세트는 추정된 평균 테스트 오류 주위에 통계적 불확실성을 의미하므로 주어진 작업에서 알고리즘 A가 알고리즘 B보다 더 잘 작동한다고 주장하기 어렵다.

데이터 세트에 수십만 개 이상의 예가 있는 경우 이는 심각한 문제가 아닙니다. 데이터 세트가 너무 작을 때, 다른 절차를 통해 계산 비용 증가의 가격으로 평균 테스트 오류 추정의 모든 예를 사용할 수 있는가? 이러한 절차는 원래 데이터 세트의 랜덤하게 선택된 서로 다른 하위 집합 또는 분할에 대해 훈련 및 테스트 계산을 반복하는 아이디어를 기반으로 한다. 이 중 가장 일반적인 것은 알고리즘 5.1에 표시된 k-폴드 교차 검증 절차로, 데이터 세트의 파티션이 겹치지 않는 부분 집합으로 분할되어 형성된다. 그런 다음 k개의 시행에서 평균 시험 오차를 취함으로써 시험 오차를 추정할 수 있다. 평가판 i에서는 데이터의 i번째 부분 집합이 테스트 집합으로 사용되고 나머지 데이터는 교육 집합으로 사용됩니다. 한 가지 문제는 그러한 평균 오차 추정기의 분산에 대한 편향되지 않은 추정기가 없다는 것이다(Bengio 및 Grandvalet, 2004). 그러나 근사치는 일반적으로 사용된다.

