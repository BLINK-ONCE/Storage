# 머신러닝 기초

# 5.1 학습 알고리즘
미첼이 말하길, "컴퓨터 프로그램은 어떤 종료의 작업T와 관련하여 경험 E로부터 배운다"고 한다. 성능 측정P. P에 의해 측정 된대로 T의 작업에서의 성능, E경험을 통해 향상된다. 

## 5.1.1  과제 The Task, T
머신러닝으로 많은 종류의 작업을 해결할 수 있다. 일반적인 기계 학습 작업에는 다음이 포함된다.

### 분류 Classification
k개의 카테고리 입력을 받는다. Task를 해결하기 위해 학습 알고리즘은 보통아래와 같다. <br>

- f: Rn -> {1, ... , k} 함수를 생성하도록 요청한다.
- y = f(x), 모델은 벡터 x로 묘사되는 input을 categories에 할당한다.assign
- 여기서 f는 클래스에 대한 확률 분포를 출력한다.(where f outputs a probability distribution over classes.)

#### classification task의 예: 객체 인식.
이미지 (일반적으로 픽셀 밝기 값의 집합으로 설명 됨)를 입력하고 이미지의 객체를 구별하는 숫자 코드를 출력.

### 입력이 없는 분류 Classification with missing inputs
추가바람

### 회귀 Regression
회귀에서 컴퓨터 프로그램은 일부 주어진input 숫자 값을 예측하도록 요청받는다. 여기서 학습 알고리즘은 f: Rn -> R 출력을 요청받는다. 이건 분류Classification과 비슷하고, 출력 형식이 다르다. 회귀 작업regression task의 예시는 증권 예측이다.

### 전사 Transcription
어떤 종류의 데이터의 상대적으로 구조화되지 않은Unstructured representation 것을 관찰하고 불연속적인(이산discrete) 텍스트 형식으로 기록한다. 예: 광학문자 인식. 컴퓨터 프로그램에게 사진을 보여준다. 텍스트 이미지를 담은 사진을. 그리고 이 텍스트(문자의 시퀀스 형태)를 반환하도록 요청받는다. 반환예시: 아스키코드, 유니코드. 이는 google 스트리트 뷰에서 주소 번호를 처리하는 딥 러닝에도 쓰이고, 현대 음성 인식 시스템을 이루는 딥러닝에도 쓰인다.

### 기계 번역 Machine translation
이미 기호symbol의 시퀀스로 이루어진 것을 입력한다. 그리고 컴퓨터 프로그램은 변환convert해야 한다. 이것을 다른 언어에서 기호의 시퀀스로. 이건 보통 영어 -> 프랑스어처럼 자연어natural languages에 적용된다.

### 구조화된 출력 Structured output
structred output task는 다음과 같은 것을 포함한다. 아웃풋이 다른 요소elements랑 중요한 관계important relationships를 가진 벡터(혹은 여러 값multiple values을 가진 데이터 구조data structure)인 것. 이건 넓은 카테고리이다. 그리고 위에 설명한 전사transcription, 번역tanslation task를 포함subsumes하고 또 다른 많은 것들도 포함한다. 예시: 구문분석parsing. 구문분석은 자연여 문장을 문법 구조를 설명하는 트리로 변환한다. 그리고 트리의 노드를 동사, 명사 또는 부사 등으로 태그를 붙인다. 예시: 이미지의 픽셀단위 분할pixel-wise segmentation of images. 컴퓨터 프로그램이 이미지의 모든 픽셀을 특정 카테고리에 할당하는 것이다. 예를 들어, 딥러닝을 사용해 항공사진의 도로의 위치locations of roads in aerial photographs에 주석annotate을 달 수 있다. 예시: 이미지 캡셔닝image captioning. 컴퓨터 프로그램은 이미지를 관찰한다. 그리고 이미지를 표현, 묘사하는 자연어로된 문장을 출력한다. 이런 작업은 구조화된 출력 작업이라한다. 왜냐면 프로그램은 반드시 서로 밀접하게 관련된 값을 출력해야 한다. 예를 들어, 이미지 캡션 프로그램은 유효한 문장valid sentence를 구성form해야 한다.

### 이상탐지 Anomaly detection
컴퓨터 프로그램은 일련의 사건이나 사물을 훑어보고sift through, 그것들 중 특이하거나unusual 비전형적인atypical 것을 표시flags한다. 예시: 신용카드 사기credit card fraud. 고객의 구매 습관을 모델링해서 신용카드 회사가 카드 오용을 감지한다. 도둑이 신용카드나 신용카드 정보를 훔친 경우 도둑은 평소와 다른 구매 패턴을 가진다. (different probability distribution over purchase types than your own.) 신용카드 회사는 계좌accounts를 정지hold 하여 사기fraud를 방지할 수 있다.

### 합성 및 샘플링 Synthesis and sampling
머신러닝은 traning data와 유사한 새로운 예시examples를 생성generate하도록 요구받는다. 머신러닝을 활용한 합성 및 샘플링은 (아티스트가 큰 규모large volume의 컨텐츠를 손으로 만들어내기에 비싸거나 지루한) 미디어 어플리케이션에 유용하게 쓰일 수 있다. 예를 들어, 비디오 게임이 (아티스트가 수동으로 각각의 픽셀을 건드리는 것 대신manually label each pixel) 자동으로 큰 물체나 풍경의 텍스쳐textures for large objects or landscapes를 만들어낸다generate. 예시: speech synthesis task(TTS를 말하는 듯) 

### 결측값 대치 Imputation of missing values
머신러닝 알고리즘은 새로운 예시new exampe를 받는다. x가 R^n 의 요소. 여기서 x의 결측missing인 xi를. 여기서 알고리즘은 결측값의 예측값prediction of the values of missing을 제공provide해야 한다.

### 노이즈 제거 Denoising
머신러닝 알고리즘은 알 수 없는 손상 과정unknown corruption process에서 얻은obtained 손상된 예를 받는다 (~x가 R^n의 요소). 여기서 깨끗한 예를 도출해야 한다(x가 R^n의 요소). learner must predict the clean example x from its corrupted version ~x. 또는 조건부 확률 분포를 예측한다. p( x | ~x)

### 밀도추청 또는 확률 질량 함수 추청 Density estimation or probability mass function estimation



# 5.1.2 성능 측정 Performance Measure, P
- 머신러닝 알고리즘의 성능을 평가하기 위해서, 우리는 그것의 성능performance을 정략적으로 분석quantitative measure할 것을 만들어야design한다. 일반적으로 이 P는 시스템이 수행하는 T에 한정specific to된다. 
- 예를 들어, 입력이 없는 분류나 전사의 경우 우리는 모델model의 정확도accuracy를 측청한다. 정확도는 단순히 모델이 제대로된 출력을 내는가에 대한 비율이다. 반대로 모델이 잘못된 출력을 내는가에 대한 비율인 오류율error rate를 측정해 같은 정보를 얻을 수 있다.
- error rate를 보통 0-1손실loss라고 한다. 올바르게 분류된 경우 0이고 그렇지 않은 경우1이다. 밀도 추정density estimation과 같은 작업의 경우, 정확도, 오류율 또는 다른 종류의 0-1손실을 측정하는 것은 의미가 없다. 대신 각 예에 대해 연속값 점수를 제공하는 다른 성능 메트릭performance metric을 사용해야 한다. 가장 일반적인 방법은 모형이 일부 예에 할당하는 평균 로그 확률을 보고하는 것이다.
- 일반적으로 머신러닝 알고리즘이 이전에 보지 못한 데이터에 대해 얼마나 잘 수행하냐에 관심이 있다. 이것이 실제 환경에서 머신러닝 알고리즘이 얼마나 잘 작동하는지를 결정하기 때문이다. 따라서 우리는 기계 학습 시스템 훈련에 사용되는 데이터와 분리된 테스트 데이터 세트를 사용하여 이러한 성능 측정을 평가한다. 성능 측정의 선택은 간단하고 객관적으로 보일 수 있지만, 종종 시스템의 원하는 동작과 잘 일치하는 성능 측정치를 선택하는 것은 어렵다.
- 예를 들어, 전사 작업을 수행할 때 전체 시퀀스를 전사할 때 시스테므이 정확도를 측정해야 하는가, 아니면 시퀀스의 일부 요소를 정확하도록 부분 크레딧을 제공하는 더 세분화된 성능 측정을 사용해야 하는가?
- 회귀 작업을 수행할 때 시스템이 중간 크기의 실수를 자주 하거나 매우 큰 실수를 거의 하지 않는 경우 시스템에 더 많은 불이익을 주어야 하는가?
- 이것에 대한 설계 선택은 애플리케이션에 따라 다릅니다. 다른 경우에는 측정하고자 하는 수량을 알고 있지만, 측정한다는 것은 비현실적입니다. 예를 들어, 이것은 밀도 추정의 맥락에서 자주 발생합니다. 최고의 확률론적 모델 중 많은 것들이 확률 분포를 암시적으로만 나타낸다. 그러한 많은 모델에서 공간의 특정 지점에 할당된 실제 확률 값을 계산하는 것은 다루기 어렵다. 이러한 경우 설계 목적과 여전히 일치하는 대체 기준을 설계하거나 원하는 기준에 대한 근사치를 설계해야 한다.


# 경험 The Experience, E
- 기계 학습 알고리즘은 학습 과정 동안 어떤 종류의 경험을 할 수 있는지에 따라 감독되지 않거나 감독되지 않은 것으로 광범위하게 분류될 수 있다. 이 책에 수록된 대부분의 학습 알고리즘은 전체 데이터 집합을 경험할 수 있는 것으로 이해할 수 있습니다. 데이터 세트는 섹션 5.1.1에 정의된 많은 예들의 모음입니다. 때로는 데이터 포인트라고도 합니다.
- 통계학자와 기계 학습 연구자가 연구한 가장 오래된 데이터 세트 중 하나는 Iris 데이터 세트이다(Fisher, 1936. 그것은 150개의 홍채 식물의 다른 부분들의 측정들의 집합이다. 각 개별 식물은 한 가지 예에 해당합니다. 각 예에 포함된 특징은 식물의 각 부분의 측정값입니다: 봉제 길이, 봉제 폭, 꽃잎 길이 및 꽃잎 폭. 데이터 집합에는 또한 각 식물이 어떤 종에 속하는지 기록되어 있습니다. 데이터 집합에는 세 가지 다른 종이 표시됩니다.

## 비지도 학습 알고리즘
많은 특징을 포함하는 데이터 집합을 경험한 다음 이 데이터 집합의 구조의 유용한 속성을 학습한다. 딥 러닝의 맥락에서, 우리는 일반적으로 밀도 추정에서처럼 명시적으로든 또는 합성 또는 노이즈 제거와 같은 작업에 대해 암시적으로든 데이터 세트를 생성한 전체 확률 분포를 학습하고자 한다. 일부 다른 비지도 학습 알고리즘은 데이터 집합을 유사한 예제의 클러스터로 나누는 것으로 구성된 클러스터링과 같은 다른 역할을 수행한다.

## 지도 학습 알고리즘
기능을 포함하는 데이터 집합을 경험하지만, 각 예는 레이블 또는 대상과 연관되기도 한다. 예를 들어, Iris 데이터 세트에는 각 홍채 식물의 종류가 주석이 달려 있습니다. 지도 학습 알고리즘은 아이리스 데이터 세트를 연구할 수 있으며, 홍채 식물을 측정에 따라 세 가지 다른 종으로 분류하는 방법을 배울 수 있다.

- 대략적으로, 감독되지 않은 학습은 랜덤 벡터 x의 몇 가지 예를 관찰하고, 그 분포의 확률 분포 p(x) 또는 몇 가지 흥미로운 속성을 암묵적으로 또는 명시적으로 학습하려고 시도하는 것을 포함한다. 반면, 감독된 학습은 랜덤 벡터 x와 관련된 값 또는 벡터 x의 몇 가지 예를 관찰하는 것을 포함한다.ry, 그리고 x로부터 y를 예측하는 것을 배우는 것 , 보통 p(y | x)를 추정합니다. 감독 학습이라는 용어는 기계 학습 시스템에 무엇을 해야 하는지를 보여주는 강사 또는 교사가 제공하는 목표의 관점에서 유래한다. 감독되지 않은 학습에는 강사나 교사가 없으며, 알고리즘은 이 가이드 없이 데이터를 이해하는 법을 배워야 한다.
- 비지도 학습과 지도 학습은 공식적으로 정의된 용어가 아니다. 그들 사이의 경계는 종종 흐릿하다. 많은 기계 학습 기술을 사용하여 두 작업을 모두 수행할 수 있습니다. 예를 들어, 확률의 체인 규칙은 벡터 x β Rn의 경우, 다음과 같이 결합 분포를 분해할 수 있다고 말한다.
p(x) =n (PI) i=1  p(xi | x1, . . . , xi−1). 
- 이 분해는 우리가 표면적으로 감독되지 않은 p(x) 모델링 문제를 감독되지 않은 학습 문제로 분할하여 해결할 수 있음을 의미한다. 또는, 우리는 전통적인 비지도 학습 기술을 사용하여 공동 분포 p(x, y)를 학습하고 유추함으로써 학습 p(y | x)의 지도 학습 문제를 해결할 수 있다.
- 감독되지 않은 학습과 감독되지 않은 학습이 완전히 형식적이거나 뚜렷한 개념은 아니지만, 그것들은 우리가 기계 학습 알고리즘으로 하는 일 중 일부를 대략적으로 분류하는 데 도움이 된다. 전통적으로 사람들은 회귀, 분류 및 구조화된 출력 문제를 지도 학습이라고 한다. 다른 작업을 지원하는 밀도 추정은 일반적으로 감독되지 않은 학습으로 간주된다.
- 학습 패러다임의 다른 변형이 가능하다. 예를 들어, 반지도 학습에서 일부 예에는 감독 대상이 포함되지만 다른 예에는 포함되지 않습니다. 다중 인스턴스 학습에서 전체 예제 모음은 클래스의 예를 포함하거나 포함하지 않는 것으로 레이블이 지정되지만 컬렉션의 개별 구성원은 레이블이 지정되지 않습니다. 심층 모델을 사용한 다중 인스턴스 학습의 최근 예는 Kotzias 등(2015)을 참조한다. 일부 기계 학습 알고리즘은 고정된 데이터 집합만 경험하지 않습니다. 예를 들어 강화 학습 알고리즘은 환경과 상호 작용하기 때문에 학습 시스템과 경험 사이에 피드백 루프가 있다. 그러한 알고리즘은 이 책의 범위를 벗어난다. 강화 학습에 대한 자세한 내용은 Sutton and Barto(1998) 또는 Bertsekas 및 Tsitsiklis(1996)를 참조하고 강화 학습에 대한 심층 학습 접근방식은 Mnih 등(2013)을 참조하십시오.
- 대부분의 기계 학습 알고리즘은 단순히 데이터 집합을 경험한다. 데이터 세트는 여러 가지 방법으로 설명할 수 있습니다. 모든 경우에 데이터 집합은 예제 모음이며, 그 다음에는 기능 모음입니다. 데이터 집합을 설명하는 일반적인 방법 중 하나는 설계 행렬을 사용하는 것입니다. 설계 행렬은 각 행에 서로 다른 예를 포함하는 행렬입니다. 행렬의 각 열은 다른 형상에 해당된다. 예를 들어 Iris 데이터 세트에는 각 예에 대해 네 가지 기능이 포함된 150개의 예가 포함되어 있습니다. 즉, 설계 행렬 X → R150×4로 데이터 세트를 나타낼 수 있습니다. 여기서 Xi, 1은 공장 i의 분리 길이, Xi, 2는 공장 i의 분리 폭입니다. 이 책에서는 대부분의 학습 알고리즘을 설계 매트릭스 데이터셋에서 작동하는 방법에 대해 설명합니다.
- 물론, 데이터 집합을 설계 행렬로 설명하기 위해서는 각 예를 벡터로 설명할 수 있어야 하며, 각 벡터는 크기가 같아야 합니다. 이것이 항상 가능한 것은 아니다. 예를 들어, 폭과 높이가 다른 사진 컬렉션이 있는 경우 다른 사진에는 서로 다른 픽셀 수가 포함되므로 모든 사진이 동일한 길이의 벡터로 설명되지는 않습니다. 제9.7절과 제10장에서는 이러한 이기종 데이터의 다른 유형을 처리하는 방법을 설명한다.
- 이러한 경우에는 데이터 집합을 m 행이 있는 행렬로 설명하지 않고 m 요소 {x(1)}, x(2), . . . x(m)}를 포함하는 집합으로 설명하겠습니다. 이 표기법은 두 개의 예제 벡터 x(i)와 x(j)의 크기가 같다는 것을 의미하지 않습니다.
- 지도 학습의 경우, 예제에는 레이블이나 대상뿐만 아니라 특징 집합도 포함되어 있습니다. 예를 들어, 학습 알고리즘을 사용하여 사진으로부터 객체 인식을 수행하려는 경우 각 사진에 나타나는 객체를 지정해야 합니다.
- 우리는 숫자 코드로 이것을 할 수 있습니다. 0은 사람을, 1은 차를, 2는 고양이를, 그리고 2는 사람을 나타냅니다. 종종 형상 관측치 X의 설계 행렬을 포함하는 데이터 집합으로 작업할 때 y는 레이블 y의 벡터를 제공하고 y는 i와 같은 레이블을 제공한다. 물론 레이블은 단일 숫자 이상일 수도 있습니다.
- 예를 들어, 만약 우리가 음성 인식 시스템을 훈련시켜 전체 문장을 기록하기를 원한다면, 각각의 예시 문장의 라벨은 단어의 순서이다. 감독 및 비감독 학습에 대한 공식적인 정의가 없는 것처럼, 데이터 세트 또는 경험에 대한 엄격한 분류법은 없다. 여기에 설명된 구조는 대부분의 경우에 적용되지만 새로운 애플리케이션을 위한 새로운 구조를 설계하는 것은 항상 가능합니다.